// Core type definitions for AI Chain Discussion Platform

export type AIProvider = 'claude' | 'openai' | 'gemini';
export type EffortLevel = 'low' | 'medium' | 'high' | 'max';
export type NodeStatus = 'idle' | 'running' | 'success' | 'error' | 'warning';

export interface AINodeData {
  label: string;
  provider: AIProvider;
  model: string;
  systemPrompt: string;
  userPromptTemplate: string;
  effort: EffortLevel;
  temperature: number;
  maxTokens: number;
  status: NodeStatus;
  output: string;
  error: string;
  tokenCount: number;
  latencyMs: number;
  enableMetaPrompt: boolean;
}

export interface EncryptedPayload {
  ciphertext: string; // base64
  iv: string;         // base64
  salt: string;       // base64
}

export interface ApiKeyEntry {
  provider: AIProvider;
  encrypted: EncryptedPayload;
}

export interface ProviderConfig {
  apiKey: EncryptedPayload | null;
  baseUrl: string; // custom base URL for proxy/relay APIs
}

export interface MemoryContext {
  l1: string;
  l2: string;
  l3: string;
}

export interface ExecutionResult {
  nodeId: string;
  output: string;
  tokenCount: number;
  latencyMs: number;
  error?: string;
}

export interface ChatRequestBody {
  provider: AIProvider;
  model: string;
  apiKey: string;
  baseUrl?: string; // custom base URL for proxy APIs
  systemPrompt: string;
  userPrompt: string;
  temperature: number;
  maxTokens: number;
  effort: EffortLevel;
  enableMetaPrompt: boolean;
}

export interface StreamChunk {
  type: 'text' | 'thinking' | 'error' | 'done';
  content: string;
}

export interface ChatMessage {
  id: string;
  role: 'user' | 'assistant' | 'system';
  content: string;
  provider?: AIProvider;
  model?: string;
  timestamp: number;
  tokenCount?: number;
  latencyMs?: number;
  error?: string;
  isStreaming?: boolean;
}

export interface Conversation {
  id: string;
  title: string;
  messages: ChatMessage[];
  provider: AIProvider;
  model: string;
  systemPrompt?: string; // custom system prompt set by /coder, /writer, etc.
  createdAt: number;
  updatedAt: number;
}

export const MODEL_OPTIONS: Record<AIProvider, string[]> = {
  claude: [
    // Opus 4.x ç³»åˆ—
    'claude-opus-4-6', 'claude-opus-4-5-20251101', 'claude-opus-4-5',
    // Sonnet 4.x ç³»åˆ—
    'claude-sonnet-4-6', 'claude-sonnet-4-5-20250929', 'claude-sonnet-4-5', 'claude-sonnet-4-20250514',
    // 3.x ç³»åˆ—
    'claude-3-7-sonnet-20250219',
    // Haiku
    'claude-haiku-4-5',
  ],
  openai: [
    'gpt-4o', 'gpt-4o-mini', 'o1-preview', 'o1-mini',
    'gpt-4-turbo', 'gpt-4', 'gpt-3.5-turbo',
    'chatgpt-4o-latest',
    // ä¸­è½¬APIç‰¹æœ‰æ¨¡å‹
    'kiro-deepseek-3-2', 'kiro-minimax-m2-1',
  ],
  gemini: ['gemini-2.0-flash', 'gemini-1.5-pro', 'gemini-1.5-flash'],
};

export const DEFAULT_BASE_URLS: Record<AIProvider, string> = {
  claude: 'https://api.anthropic.com',
  openai: 'https://api.openai.com',
  gemini: 'https://generativelanguage.googleapis.com',
};

// Model strength ranking â€” higher score = stronger model
// Used by QuickSetup to auto-select the best available model
export const MODEL_STRENGTH: Record<string, { score: number; provider: AIProvider }> = {
  // Claude family (strongest first)
  'claude-opus-4-6': { score: 102, provider: 'claude' },
  'claude-opus-4-5-20251101': { score: 101, provider: 'claude' },
  'claude-opus-4-5': { score: 101, provider: 'claude' },
  'claude-opus-4-20250514': { score: 100, provider: 'claude' },
  'claude-4-opus': { score: 100, provider: 'claude' },
  'claude-opus-4': { score: 100, provider: 'claude' },
  'claude-sonnet-4-6': { score: 97, provider: 'claude' },
  'claude-sonnet-4-5-20250929': { score: 96, provider: 'claude' },
  'claude-sonnet-4-5': { score: 96, provider: 'claude' },
  'claude-sonnet-4-20250514': { score: 95, provider: 'claude' },
  'claude-4-sonnet': { score: 95, provider: 'claude' },
  'claude-sonnet-4': { score: 95, provider: 'claude' },
  'claude-3-7-sonnet-20250219': { score: 91, provider: 'claude' },
  'claude-3.5-sonnet': { score: 90, provider: 'claude' },
  'claude-3-5-sonnet': { score: 90, provider: 'claude' },
  'claude-3-5-sonnet-20241022': { score: 90, provider: 'claude' },
  'claude-3-5-sonnet-latest': { score: 90, provider: 'claude' },
  'claude-3-opus': { score: 88, provider: 'claude' },
  'claude-3-opus-20240229': { score: 88, provider: 'claude' },
  'claude-3-sonnet': { score: 75, provider: 'claude' },
  'claude-3-sonnet-20240229': { score: 75, provider: 'claude' },
  'claude-3.5-haiku': { score: 70, provider: 'claude' },
  'claude-3-5-haiku': { score: 70, provider: 'claude' },
  'claude-haiku-4-5': { score: 70, provider: 'claude' },
  'claude-3-haiku': { score: 60, provider: 'claude' },
  'claude-haiku-20241022': { score: 60, provider: 'claude' },
  // OpenAI family
  'o1-preview': { score: 98, provider: 'openai' },
  'o1': { score: 97, provider: 'openai' },
  'gpt-4o': { score: 92, provider: 'openai' },
  'chatgpt-4o-latest': { score: 92, provider: 'openai' },
  'gpt-4-turbo': { score: 85, provider: 'openai' },
  'gpt-4': { score: 82, provider: 'openai' },
  'gpt-4o-mini': { score: 72, provider: 'openai' },
  'o1-mini': { score: 78, provider: 'openai' },
  'gpt-3.5-turbo': { score: 55, provider: 'openai' },
  // Gemini family
  'gemini-2.0-flash': { score: 80, provider: 'gemini' },
  'gemini-1.5-pro': { score: 85, provider: 'gemini' },
  'gemini-1.5-flash': { score: 70, provider: 'gemini' },
};

// Given a list of model names, pick the strongest one
export function pickStrongestModel(models: string[]): { model: string; provider: AIProvider; score: number } | null {
  let best: { model: string; provider: AIProvider; score: number } | null = null;

  for (const m of models) {
    const lower = m.toLowerCase();
    // Direct match
    const info = MODEL_STRENGTH[lower] || MODEL_STRENGTH[m];
    if (info && (!best || info.score > best.score)) {
      best = { model: m, provider: info.provider, score: info.score };
      continue;
    }
    // Fuzzy match: check if any known key is a substring
    for (const [key, val] of Object.entries(MODEL_STRENGTH)) {
      if (lower.includes(key) || key.includes(lower)) {
        if (!best || val.score > best.score) {
          best = { model: m, provider: val.provider, score: val.score };
        }
      }
    }
  }

  // If no match found, try to guess provider from name
  if (!best && models.length > 0) {
    const m = models[0];
    const lower = m.toLowerCase();
    const provider: AIProvider = lower.includes('claude') ? 'claude'
      : lower.includes('gemini') ? 'gemini'
      : 'openai';
    best = { model: m, provider, score: 0 };
  }

  return best;
}

// Detect provider from a model name string
export function detectProvider(model: string): AIProvider {
  const lower = model.toLowerCase();
  if (lower.includes('claude')) return 'claude';
  if (lower.includes('gemini')) return 'gemini';
  return 'openai'; // default â€” most relays use OpenAI-compatible format
}

// Fuzzy-match a parsed model name against actual available models from relay
// Handles common mismatches: dotsâ†”dashes (4.5 vs 4-5), missing dates, etc.
export function fuzzyMatchModel(parsed: string, available: string[]): string | null {
  if (!parsed || available.length === 0) return null;
  const lower = parsed.toLowerCase();
  // 1. Exact match
  if (available.includes(parsed)) return parsed;
  const exactLower = available.find(m => m.toLowerCase() === lower);
  if (exactLower) return exactLower;
  // 2. Normalize: replace dots with dashes (4.5 â†’ 4-5)
  const normalized = lower.replace(/\./g, '-');
  const normMatch = available.find(m => m.toLowerCase() === normalized);
  if (normMatch) return normMatch;
  // 3. Substring match: find model that contains the normalized name or vice versa
  const subMatch = available.find(m => {
    const ml = m.toLowerCase();
    const mn = ml.replace(/\./g, '-');
    return mn.includes(normalized) || normalized.includes(mn);
  });
  if (subMatch) return subMatch;
  // 4. No match
  return null;
}

export const DEFAULT_NODE_DATA: AINodeData = {
  label: 'æ–°èŠ‚ç‚¹',
  provider: 'claude',
  model: 'claude-sonnet-4-20250514',
  systemPrompt: 'ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚',
  userPromptTemplate: '{{prev.output}}\n\n{{user.input}}',
  effort: 'medium',
  temperature: 0.7,
  maxTokens: 4096,
  status: 'idle',
  output: '',
  error: '',
  tokenCount: 0,
  latencyMs: 0,
  enableMetaPrompt: false,
};

// ===== Agent Tool Definitions =====

export type AgentToolName = 'terminal' | 'readFile' | 'writeFile' | 'listDir' | 'search';

export interface AgentTool {
  name: AgentToolName;
  label: string;
  description: string;
  icon: string;
}

export const ALL_AGENT_TOOLS: AgentTool[] = [
  { name: 'terminal', label: 'ç»ˆç«¯æ‰§è¡Œ', description: 'æ‰§è¡Œ shell å‘½ä»¤ï¼ˆnpm, git, go, python ç­‰ï¼‰', icon: 'ğŸ’»' },
  { name: 'readFile', label: 'è¯»å–æ–‡ä»¶', description: 'è¯»å–æŒ‡å®šè·¯å¾„çš„æ–‡ä»¶å†…å®¹', icon: 'ğŸ“–' },
  { name: 'writeFile', label: 'å†™å…¥æ–‡ä»¶', description: 'åˆ›å»ºæˆ–ä¿®æ”¹æ–‡ä»¶', icon: 'âœï¸' },
  { name: 'listDir', label: 'ç›®å½•åˆ—è¡¨', description: 'åˆ—å‡ºç›®å½•ä¸‹çš„æ–‡ä»¶å’Œå­ç›®å½•', icon: 'ğŸ“' },
  { name: 'search', label: 'æœç´¢æ–‡ä»¶', description: 'åœ¨é¡¹ç›®ä¸­æœç´¢æ–‡ä»¶æˆ–å†…å®¹', icon: 'ğŸ”' },
];

// Which tools each role type gets by default
export const ROLE_TOOL_PRESETS: Record<string, AgentToolName[]> = {
  'æ¶æ„å¸ˆ': ['readFile', 'listDir', 'search'],
  'è¯„å®¡å‘˜': ['readFile', 'listDir', 'search', 'terminal'],
  'äº§å“ç»ç†': ['readFile', 'listDir'],
  'å‰ç«¯å·¥ç¨‹å¸ˆ': ['terminal', 'readFile', 'writeFile', 'listDir', 'search'],
  'åç«¯å·¥ç¨‹å¸ˆ': ['terminal', 'readFile', 'writeFile', 'listDir', 'search'],
  'æ€»ç»“è€…': ['readFile', 'listDir'],
};

// Build tool description string for injection into system prompt
export function buildToolPrompt(tools: AgentToolName[]): string {
  if (tools.length === 0) return '';
  const toolDescs = tools.map((t) => {
    const tool = ALL_AGENT_TOOLS.find((at) => at.name === t);
    if (!tool) return '';
    return `- **${tool.label}** (${tool.name}): ${tool.description}`;
  }).filter(Boolean).join('\n');

  return `\n\n## å¯ç”¨å·¥å…·\nä½ å¯ä»¥åœ¨å›å¤ä¸­ä½¿ç”¨ä»¥ä¸‹å·¥å…·ã€‚ä½¿ç”¨æ—¶è¯·ç”¨ \`\`\`tool:å·¥å…·å\`\`\` ä»£ç å—æ ¼å¼ï¼š\n${toolDescs}\n\n### å·¥å…·è°ƒç”¨æ ¼å¼ç¤ºä¾‹\n\`\`\`tool:terminal\nnpm run build\n\`\`\`\n\n\`\`\`tool:readFile\n/path/to/file.ts\n\`\`\`\n\n\`\`\`tool:writeFile:/path/to/file.ts\næ–‡ä»¶å†…å®¹...\n\`\`\`\n\n\`\`\`tool:listDir\n/path/to/directory\n\`\`\`\n\n\`\`\`
grep -r "pattern" /path\n\`\`\`\n\nè¯·åœ¨éœ€è¦æ—¶ä¸»åŠ¨ä½¿ç”¨å·¥å…·æ¥éªŒè¯æ–¹æ¡ˆã€æŸ¥çœ‹ä»£ç æˆ–æ‰§è¡Œå‘½ä»¤ã€‚`;
}

// ===== Chain Discussion Types =====

export type ChainExecutionMode = 'sequential' | 'parallel';

// A single agent node in the discussion chain
export interface ChainAgent {
  id: string;
  name: string;           // e.g. "æ¶æ„å¸ˆ", "è¯„å®¡å‘˜", "äº§å“ç»ç†"
  role: string;           // system prompt describing this agent's role
  provider: AIProvider;
  model: string;
  temperature: number;
  maxTokens: number;
  color: string;          // avatar color for UI
  icon: string;           // emoji icon
  tools: AgentToolName[]; // which tools this agent can use
}

// One turn of output from an agent
export interface ChainTurn {
  id: string;
  agentId: string;
  agentName: string;
  model: string;
  content: string;
  tokenCount: number;
  latencyMs: number;
  error?: string;
  isStreaming?: boolean;
  timestamp: number;
}

// A complete chain discussion session
export interface ChainDiscussion {
  id: string;
  title: string;
  topic: string;          // the user's original requirement/question
  agents: ChainAgent[];
  turns: ChainTurn[];
  rounds: number;         // how many rounds of discussion
  currentRound: number;
  mode: ChainExecutionMode;
  status: 'idle' | 'running' | 'paused' | 'completed' | 'error';
  createdAt: number;
  updatedAt: number;
}

// Preset agent templates
export const AGENT_PRESETS: Omit<ChainAgent, 'id'>[] = [
  {
    name: 'æ¶æ„å¸ˆ',
    role: 'ä½ æ˜¯ä¸€ä½èµ„æ·±è½¯ä»¶æ¶æ„å¸ˆã€‚ä½ è´Ÿè´£ä»ç³»ç»Ÿè®¾è®¡ã€å¯æ‰©å±•æ€§ã€æŠ€æœ¯é€‰å‹çš„è§’åº¦åˆ†æé—®é¢˜ï¼Œæå‡ºæ¶æ„æ–¹æ¡ˆã€‚è¯·åŸºäºå‰é¢çš„è®¨è®ºå†…å®¹ç»™å‡ºä½ çš„ä¸“ä¸šæ„è§ã€‚',
    provider: 'claude',
    model: 'claude-opus-4-6',
    temperature: 0.7,
    maxTokens: 4096,
    color: '#6366f1',
    icon: 'ğŸ—ï¸',
    tools: ['readFile', 'listDir', 'search'],
  },
  {
    name: 'è¯„å®¡å‘˜',
    role: 'ä½ æ˜¯ä¸€ä½ä¸¥æ ¼çš„ä»£ç è¯„å®¡ä¸“å®¶ã€‚ä½ è´Ÿè´£å®¡æŸ¥æ–¹æ¡ˆä¸­çš„æ½œåœ¨é—®é¢˜ã€å®‰å…¨éšæ‚£ã€æ€§èƒ½ç“¶é¢ˆï¼Œå¹¶æå‡ºæ”¹è¿›å»ºè®®ã€‚è¯·åŸºäºå‰é¢çš„è®¨è®ºå†…å®¹ç»™å‡ºä½ çš„è¯„å®¡æ„è§ã€‚',
    provider: 'claude',
    model: 'claude-sonnet-4-5',
    temperature: 0.5,
    maxTokens: 4096,
    color: '#f59e0b',
    icon: 'ğŸ”',
    tools: ['readFile', 'listDir', 'search', 'terminal'],
  },
  {
    name: 'äº§å“ç»ç†',
    role: 'ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„äº§å“ç»ç†ã€‚ä½ è´Ÿè´£ä»ç”¨æˆ·éœ€æ±‚ã€å•†ä¸šä»·å€¼ã€ä¼˜å…ˆçº§æ’åºçš„è§’åº¦åˆ†æé—®é¢˜ã€‚è¯·åŸºäºå‰é¢çš„è®¨è®ºå†…å®¹ç»™å‡ºä½ çš„äº§å“è§†è§’ã€‚',
    provider: 'claude',
    model: 'claude-sonnet-4-6',
    temperature: 0.7,
    maxTokens: 4096,
    color: '#10b981',
    icon: 'ğŸ“‹',
    tools: ['readFile', 'listDir'],
  },
  {
    name: 'å‰ç«¯å·¥ç¨‹å¸ˆ',
    role: 'ä½ æ˜¯ä¸€ä½èµ„æ·±å‰ç«¯å·¥ç¨‹å¸ˆï¼Œç²¾é€š Vue3/React/TypeScriptã€‚ä½ è´Ÿè´£ä»å‰ç«¯å®ç°ã€ç”¨æˆ·ä½“éªŒã€ç»„ä»¶è®¾è®¡çš„è§’åº¦åˆ†æé—®é¢˜ã€‚è¯·åŸºäºå‰é¢çš„è®¨è®ºå†…å®¹ç»™å‡ºä½ çš„æŠ€æœ¯æ–¹æ¡ˆã€‚',
    provider: 'claude',
    model: 'claude-sonnet-4-5-20250929',
    temperature: 0.6,
    maxTokens: 4096,
    color: '#3b82f6',
    icon: 'ğŸ¨',
    tools: ['terminal', 'readFile', 'writeFile', 'listDir', 'search'],
  },
  {
    name: 'åç«¯å·¥ç¨‹å¸ˆ',
    role: 'ä½ æ˜¯ä¸€ä½èµ„æ·±åç«¯å·¥ç¨‹å¸ˆï¼Œç²¾é€š Go/Java/Pythonã€‚ä½ è´Ÿè´£ä»åç«¯å®ç°ã€æ•°æ®åº“è®¾è®¡ã€APIè®¾è®¡çš„è§’åº¦åˆ†æé—®é¢˜ã€‚è¯·åŸºäºå‰é¢çš„è®¨è®ºå†…å®¹ç»™å‡ºä½ çš„æŠ€æœ¯æ–¹æ¡ˆã€‚',
    provider: 'claude',
    model: 'claude-sonnet-4-5',
    temperature: 0.6,
    maxTokens: 4096,
    color: '#8b5cf6',
    icon: 'âš™ï¸',
    tools: ['terminal', 'readFile', 'writeFile', 'listDir', 'search'],
  },
  {
    name: 'æ€»ç»“è€…',
    role: 'ä½ æ˜¯ä¸€ä½å–„äºæ€»ç»“çš„åè°ƒè€…ã€‚ä½ è´Ÿè´£ç»¼åˆæ‰€æœ‰äººçš„æ„è§ï¼Œæç‚¼å‡ºæœ€ç»ˆçš„ç»“è®ºå’Œè¡ŒåŠ¨è®¡åˆ’ã€‚è¯·åŸºäºå‰é¢æ‰€æœ‰è®¨è®ºå†…å®¹ï¼Œç»™å‡ºç»“æ„åŒ–çš„æ€»ç»“ã€‚',
    provider: 'claude',
    model: 'claude-opus-4-6',
    temperature: 0.5,
    maxTokens: 4096,
    color: '#ec4899',
    icon: 'ğŸ“',
    tools: ['readFile', 'listDir'],
  },
];
